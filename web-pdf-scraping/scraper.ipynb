{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "from io import BytesIO\n",
    "from typing import Dict\n",
    "\n",
    "import requests\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service('C:/webdriver/chromedriver')\n",
    "driver = webdriver.Chrome(service=Service())\n",
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = 'https://www.cse.lk/pages/cse-daily/cse-daily.component.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(search_url)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_list_class_name = 'rules-flexible'\n",
    "report_class_name = 'rules-block flexible'\n",
    "date_class_name = 'date'\n",
    "button_class_name = 'dropdown-button'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_share_price_index_pattern=r'\\((ASPI)\\)\\s+([\\d,]+\\.\\d+)\\s+([\\d,]+\\.\\d+)'\n",
    "sp_sri_lanka_20_index_pattern= r'(S&P Sri Lanka 20 Index)\\s+([\\d,]+\\.\\d+)\\s+([\\d,]+\\.\\d+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_data(text: str) -> Dict[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Extracts ASPI and S&P Sri Lanka 20 Index values from the text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing financial data.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[str, str]]: A dictionary with extracted values for ASPI and S&P Sri Lanka 20 Index.\n",
    "    \"\"\"\n",
    "    # Clean the text by removing extra spaces and newlines\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Initialize result dictionary\n",
    "    extracted_data = {}\n",
    "    \n",
    "    # Extract ASPI values\n",
    "    aspi_match = re.search(all_share_price_index_pattern, text)\n",
    "    if aspi_match:\n",
    "        extracted_data['ASPI'] = {\n",
    "            'Today': aspi_match.group(2),\n",
    "            'Previous': aspi_match.group(3)\n",
    "        }\n",
    "    \n",
    "    # Extract S&P Sri Lanka 20 Index values\n",
    "    sp_sri_lanka_match = re.search(sp_sri_lanka_20_index_pattern, text)\n",
    "    if sp_sri_lanka_match:\n",
    "        extracted_data['S&P Sri Lanka 20 Index'] = {\n",
    "            'Today': sp_sri_lanka_match.group(2),\n",
    "            'Previous': sp_sri_lanka_match.group(3)\n",
    "        }\n",
    "    \n",
    "    return extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text_from_url(pdf_url):\n",
    "    \"\"\"\n",
    "    Extract text from the first page of a PDF given its URL.\n",
    "    \n",
    "    Args:\n",
    "        pdf_url (str): The URL of the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: Text extracted from the first page of the PDF.\n",
    "    \"\"\"\n",
    "    # Set up headers for the request\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0',\n",
    "        'Accept': 'application/pdf,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'\n",
    "    }\n",
    "    \n",
    "    # Fetch the PDF content\n",
    "    response = requests.get(pdf_url, headers=headers)\n",
    "    response.raise_for_status()  # Ensure the request was successful\n",
    "    \n",
    "    # Extract text from the first page of the PDF\n",
    "    with pdfplumber.open(BytesIO(response.content)) as pdf:\n",
    "        if len(pdf.pages) > 0:\n",
    "            first_page_text = pdf.pages[0].extract_text()\n",
    "        else:\n",
    "            first_page_text = \"No pages found in PDF.\"\n",
    "            \n",
    "    return first_page_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "while True:\n",
    "    # Get the HTML content of the page\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    # Find the main element containing the list of reports\n",
    "    shows_element = soup.find('div', attrs={'class': report_list_class_name})\n",
    "    div_elements = shows_element.findAll('div', attrs={'class': report_class_name})\n",
    "    print(f\"Number of shows found: {len(div_elements)}\")\n",
    "    \n",
    "    for div in div_elements:\n",
    "        date_element = div.find('div', attrs={'class': date_class_name})\n",
    "        print(date_element.text)    \n",
    "        download_button = div.find('a', attrs={'class': button_class_name})\n",
    "        href = download_button['href']\n",
    "        driver.execute_script(f\"window.open('{href}', '_blank');\")\n",
    "        \n",
    "        \n",
    "        time.sleep(10)\n",
    "        \n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        pdf_url = driver.current_url\n",
    "        \n",
    "        text = extract_pdf_text_from_url(pdf_url)\n",
    "        \n",
    "        result=extract_pdf_data(text)\n",
    "        \n",
    "        # Close the PDF tab and switch back to main tab\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        data = {\n",
    "            'date': date_element.text,\n",
    "            'pdf_url': pdf_url,\n",
    "            'extracted_data': result\n",
    "        }\n",
    "        reports.append(data)\n",
    "        \n",
    "    # Close the main tab\n",
    "    driver.close()\n",
    "    \n",
    "    \n",
    "    break\n",
    "\n",
    "print(reports)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for DataFrame\n",
    "data_for_df = [\n",
    "    {\n",
    "        'Date': entry['date'].strip(),\n",
    "        'PDF URL': entry['pdf_url'],\n",
    "        'ASPI Today': entry['extracted_data']['ASPI']['Today'],\n",
    "        'ASPI Previous': entry['extracted_data']['ASPI']['Previous'],\n",
    "        'S&P 20 Today': entry['extracted_data']['S&P Sri Lanka 20 Index']['Today'],\n",
    "        'S&P 20 Previous': entry['extracted_data']['S&P Sri Lanka 20 Index']['Previous'],\n",
    "    }\n",
    "    for entry in reports\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data_for_df)\n",
    "\n",
    "# Define CSV file name\n",
    "reports_data = \"reports_data.csv\"\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(reports_data, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
